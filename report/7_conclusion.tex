\chapter{Conclusion}
\label{conclusion}
We touched on a new task for citation analysis, Citation Provenance. In this task, we are trying to locate the information in a cited paper that justifies a citation found in a citing paper.

I presented a two-tier approach towards this problem, {\it Gvs} and {\it LocateProv}. With the first acting as a filter to separate the General citations from the Specific ones and the second one to predict which of the fragments in the cited paper are referenced by the citation. One of the challenges in this task is the highly unbalanced ratio between General versus Specific citations. Also, the annotation task is very challenging and would require experienced researchers who understands the content of the papers to be annotated. As a result all the training instances were manually annotated.

To train prediction models for this task, I gathered an unskewed set of instances, a balanced ratio of General versus Specific instances, and measured their ability to differentiate between the 2 types of citations. Feature analysis showed that most of the features are essential, with the Physical Features (Feature $A$) adopted from \cite{dongensemble} proving to have the most discriminative power in {\it GvS}, and Cosine Similarity (a common strategy for Information Retrieval tasks) remained to be most important in {\it LocateProv}.

Finally, evaluations on {\it Gvs} and {\it LocateProv} produced promising results in classifying General versus Specific citations and locating the cited fragment in the cited paper.