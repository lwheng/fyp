\chapter{Conclusion}
\label{conclusion}
In our thesis, we examine a new task in citation analysis, citation provenance. While \outcite{csibs} presented the CSIBS tool that gave readers a preview of a cited paper, it does not provide information that justifies a citation. In our paper, we described the first attempt to provide a solution to the challenge of locating the origin of a citation

We presented a two-tier approach towards this problem, {\it GvS} and {\it LocateProv}. With the first acting as a filter to classify the citations into one of the two types: General and Specific. The second predicts which of the fragments in the cited paper are referenced by the citation. One of the difficulties we faced in this task is the highly unbalanced ratio between General versus Specific citations. Also, the annotation task is very challenging and would require experienced researchers who understands the content of the papers to be annotated. As a result all the training instances were manually annotated.
%=======
%In our thesis, we examine a new task in citation analysis, citation provenance. 
%% Min: I still don't know what you mean by ``summarisation solution''
%While \outcite{csibs} presented the CSIBS tool that gave readers a preview of a cited paper, it only provided a summarisation solution.
%In our paper, we described the first attempt to provide a solution to the difficulty of locating the information that justifies a citation.
%
%We presented a two-tier approach towards this problem, {\it Gvs} and {\it LocateProv}. The first tier acts as a filter to separate the General citations from the Specific ones, and the second tier takes Specific citations and predicts which fragments in the cited paper are referenced by the citation. 
%% Min: ok, but you didn't really do anything about this or assess how your system deals with this.  You need to do that in the evaluation before arguing for this.
%One of the challenges in this task is the highly unbalanced ratio between General versus Specific citations. Also, the annotation task is very challenging and would require experienced researchers who understands the content of the papers to be annotated. As a result all the training instances were manually annotated.
%>>>>>>> a6571d7fd2392c8413509bd7cc65c689bcf8404d

To train prediction models for this task, we artificially sample an unskewed set of instances, a balanced ratio of General versus Specific instances, and measured their ability to differentiate between the 2 types of citations. Feature analysis showed that most of the features are essential, with the Physical Features (Feature $A$) adopted from \outcite{dongensemble} proving to have the most discriminative power in {\it GvS}, and Cosine Similarity (a common mechanism used in Information Retrieval tasks) remained to be most important in {\it LocateProv}.

%<<<<<<< HEAD
Finally, evaluations on {\it GvS} and {\it LocateProv} produced promising results in classifying General versus Specific citations and locating the cited fragment in the cited paper. \textit{GvS} obtained an accuracy of 0.786 in our cross-validation, demonstrating its potential to perform in practice. \textit{LocateProv} showed an improvement compared to our baseline, justifying the features we introduced to target cited fragments.
%=======
%Finally, evaluations on {\it GvS} and {\it LocateProv} produced promising results in classifying General versus Specific citations and locating the cited fragment in the cited paper.
%>>>>>>> a6571d7fd2392c8413509bd7cc65c689bcf8404d
